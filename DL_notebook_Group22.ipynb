{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Reshape, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Alberto Parenti\\Downloads\\STUDY\\NOVA IMS\\DEEP LEARNING\\PROJECT\\crop_part1\"\n",
    "\n",
    "#We need a way to convert our training set into the correct format\n",
    "\n",
    "def load_real_samples(image_path):\n",
    "    \n",
    "    #Defining master array\n",
    "    master_list = list()\n",
    "\n",
    "    for image in os.listdir(image_path):\n",
    "        #loading image\n",
    "        img = load_img(os.path.join(image_path,image))\n",
    "        # convert to numpy array\n",
    "        img_array = img_to_array(img)\n",
    "\n",
    "        #img_array = tf.image.resize(img_array, [28, 28])\n",
    "        #Standardizing to float\n",
    "        img_array = img_array.astype(\"float32\")\n",
    "        #Getting value between 0 and 1\n",
    "        img_array/=255.0\n",
    "\n",
    "        master_list.append(img_array)\n",
    "\n",
    "    return np.array(master_list)\n",
    "\n",
    "array_data = load_real_samples(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 200, 200, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining image shape\n",
    "\n",
    "img_rows = 200\n",
    "img_cols = 200\n",
    "channels = 3\n",
    "\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    noise_shape = (100,) #Defining the latent vector of size 100\n",
    "\n",
    "    #Defining our model with 4 dense layers of increasing dimension\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_shape = noise_shape))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    model.add(Dense(2048))\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "    model.add(Dense(np.prod(img_shape), activation = \"tanh\"))\n",
    "    model.add(Reshape(img_shape))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #Transforming the latent space vector into an tf input\n",
    "    noise = Input(shape = noise_shape)\n",
    "    #Feeding that latent space into the model to create an image\n",
    "    img = model(noise) #Generated image\n",
    "\n",
    "    return Model(noise, img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a discriminator to guess at whether an image is real or not\n",
    "#Model has 4 layers of decreasing dimension\n",
    "\n",
    "def build_discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(1024))\n",
    "\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(512))\n",
    "\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    \n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "    #Converting the image into a tf input and passing that to the model\n",
    "    img = Input(shape=img_shape)\n",
    "    #Retrieving the output prediction from the model\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity) #The validity is whether or not the model thinks the image is real\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs, batch_size=128, save_interval=500):\n",
    "    \n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    disc_accuracy_list = []\n",
    "    disc_loss_list = []\n",
    "    generator_loss_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Discriminator Training\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of real images from our array data stored in array_data\n",
    "\n",
    "        #Storing the indexes of those images in idx\n",
    "        indx = np.random.randint(0, array_data.shape[0], half_batch)\n",
    "\n",
    "        #Retreiving those indexes from the array\n",
    "        imgs = array_data[indx]\n",
    "\n",
    "        #Generating a half batch worth of latent space vectors which will comprise half of what\n",
    "        #we feed to the discriminator\n",
    "        latent_space = np.random.normal(0, 1, (half_batch, 100))\n",
    "        \n",
    "        # Generate a half batch of fake images from the half batch of latent spaces\n",
    "        generated_imgs = generator.predict(latent_space)\n",
    "\n",
    "        # Training the discriminator on real and fake images but not at the same time, always holding one constant\n",
    "        #first on the real\n",
    "        disc_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "\n",
    "        #then on the fake generated images\n",
    "        disc_loss_fake = discriminator.train_on_batch(generated_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "        #take average loss from real and fake images. \n",
    "        disc_loss = 0.5 * np.add(disc_loss_real, disc_loss_fake) \n",
    "\n",
    "        #Now within the same for loop we train our Generator model by setting the input latent_space and\n",
    "        #ultimately training the Generator to have the Discriminator label its samples as valid or false.\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        #Create latent_space vectors as input for generator. \n",
    "        #Create as many latent_space vectors as defined by the batch size. \n",
    "        latent_space = np.random.normal(0, 1, (batch_size, 100)) \n",
    "\n",
    "        #Creating a vector of ones in order to trick the discriminator into thinking that the image is real\n",
    "        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\n",
    "\n",
    "        # Generator is part of the combined model where it paired with the discriminator\n",
    "        # Train the generator with latent_space as x and 1 as y. \n",
    "        generator_loss = combined.train_on_batch(latent_space, valid_y)\n",
    "\n",
    "\n",
    "        #In order for us to keep track of the epochs elapsed and the results we print the following\n",
    "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, disc_loss[0], 100*disc_loss[1], generator_loss))\n",
    "\n",
    "        #Appending the loss and accuracy metrics to lists\n",
    "        epoch_list.append(epoch)\n",
    "        disc_loss_list.append(disc_loss[0])\n",
    "        disc_accuracy_list.append(100*disc_loss[1])\n",
    "        generator_loss_list.append(generator_loss)\n",
    "\n",
    "        # If we are at the specified interval save generated image of samples\n",
    "        if epoch % save_interval == 0:\n",
    "            save_imgs(epoch)\n",
    "\n",
    "    #At the end of the epochs plot the discriminator loss per epoch\n",
    "    plt.plot(epoch_list, disc_loss_list)\n",
    "    plt.show()\n",
    "\n",
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    latent_space = np.random.normal(0, 1, (r * c, 100))\n",
    "    generated_imgs = generator.predict(latent_space)\n",
    "\n",
    "    # Scaling our image\n",
    "    generated_imgs = 0.5 * generated_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(generated_imgs[cnt, :,:,:])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/generation_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 120000)            0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1024)              122881024 \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,537,409\n",
      "Trainable params: 123,537,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 256)               25856     \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2048)              2099200   \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 2048)             8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 120000)            245880000 \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 200, 200, 3)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,677,312\n",
      "Trainable params: 248,669,632\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C38F6CB3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x000001C38F6E4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x000001C38F6E4A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0 [D loss: 0.778154, acc.: 31.25%] [G loss: 0.762363]\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C38F6CB3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1 [D loss: 0.403843, acc.: 52.34%] [G loss: 0.702912]\n",
      "2 [D loss: 0.364221, acc.: 71.88%] [G loss: 1.157115]\n",
      "3 [D loss: 0.582529, acc.: 51.56%] [G loss: 0.405004]\n",
      "4 [D loss: 0.609458, acc.: 60.16%] [G loss: 0.857947]\n",
      "5 [D loss: 0.412468, acc.: 75.00%] [G loss: 0.517631]\n",
      "6 [D loss: 0.206674, acc.: 89.06%] [G loss: 0.953721]\n",
      "7 [D loss: 0.395989, acc.: 84.38%] [G loss: 0.558113]\n",
      "8 [D loss: 0.413250, acc.: 82.81%] [G loss: 0.729023]\n",
      "9 [D loss: 0.455670, acc.: 80.47%] [G loss: 0.802327]\n",
      "10 [D loss: 11.802913, acc.: 14.84%] [G loss: 2.198925]\n",
      "11 [D loss: 2.663397, acc.: 72.66%] [G loss: 7.630774]\n",
      "12 [D loss: 5.727298, acc.: 64.84%] [G loss: 8.260429]\n",
      "13 [D loss: 4.168042, acc.: 70.31%] [G loss: 8.433153]\n",
      "14 [D loss: 3.923315, acc.: 67.19%] [G loss: 10.534710]\n",
      "15 [D loss: 3.058882, acc.: 67.19%] [G loss: 7.995202]\n",
      "16 [D loss: 2.820380, acc.: 65.62%] [G loss: 8.485209]\n",
      "17 [D loss: 1.587209, acc.: 68.75%] [G loss: 7.141528]\n",
      "18 [D loss: 0.470511, acc.: 83.59%] [G loss: 7.822194]\n",
      "19 [D loss: 32.150631, acc.: 21.88%] [G loss: 11.278292]\n",
      "20 [D loss: 5.958319, acc.: 69.53%] [G loss: 9.167595]\n",
      "21 [D loss: 7.326520, acc.: 71.09%] [G loss: 17.132616]\n",
      "22 [D loss: 9.766941, acc.: 71.09%] [G loss: 13.215387]\n",
      "23 [D loss: 6.457394, acc.: 70.31%] [G loss: 13.116510]\n",
      "24 [D loss: 5.169942, acc.: 70.31%] [G loss: 8.972181]\n",
      "25 [D loss: 4.976043, acc.: 70.31%] [G loss: 10.401003]\n",
      "26 [D loss: 3.701734, acc.: 72.66%] [G loss: 9.304699]\n",
      "27 [D loss: 4.483978, acc.: 71.09%] [G loss: 8.566116]\n",
      "28 [D loss: 3.100427, acc.: 71.88%] [G loss: 6.959604]\n",
      "29 [D loss: 2.692534, acc.: 75.00%] [G loss: 7.144397]\n",
      "30 [D loss: 2.582500, acc.: 71.88%] [G loss: 5.646358]\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(0.0001, 0.5)  #Learning rate and momentum.\n",
    "\n",
    "# We are first going to build the discriminator and then train the generator as part of the combined model later\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "#Building and compiling our Generator, picking the loss function and optimizer\n",
    "#Since we are generating fake images there is no need to track any metrics.\n",
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "#Creating first the input latent space and then defining the generator  \n",
    "z = Input(shape=(100,))   #Our random vector to be used as an input\n",
    "\n",
    "#Storing the image as img\n",
    "img = generator(z)\n",
    "\n",
    "#Ensuring that when we combine Discriminator and Generator networks we only train the latter \n",
    "#This is to ensure that while the generator is being trained, the weights of the discriminator are not being adjusted\n",
    "#Note that this has no impact on the discriminator training above    \n",
    "discriminator.trainable = False  \n",
    "\n",
    "#Here our generator takes our image and classifies it as either real or fake  \n",
    "r_or_f = discriminator(img) \n",
    "\n",
    "\n",
    "#Here we combine the gen and disc models and define our loss function and optimizer. \n",
    "#To be sure, we are only training the generator here-\n",
    "#The objective in this step is for the generator to fool the discriminator  \n",
    "# The final combined model  (which is a stacked generator and discriminator) takes\n",
    "# noise (latent space) as an input => generates images => determines the validity of those images\n",
    "combined = Model(z, r_or_f)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "#Setting the model with the needed params\n",
    "train(array_data,epochs=150, batch_size=128, save_interval=500)\n",
    "\n",
    "#Saving model for future use\n",
    "generator.save('image_generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "489273d9e700296fcf9e47b32fa24414c858b77e187d8a326e595227c9517409"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
